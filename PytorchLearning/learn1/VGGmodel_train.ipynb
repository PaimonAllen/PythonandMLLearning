{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.2%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=13'>14</a>\u001b[0m \u001b[39m# from VGG\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=15'>16</a>\u001b[0m train_data \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39;49mCIFAR10(root\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./dataset\u001b[39;49m\u001b[39m\"\u001b[39;49m, train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, transform\u001b[39m=\u001b[39;49mtorchvision\u001b[39m.\u001b[39;49mtransforms\u001b[39m.\u001b[39;49mToTensor(),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=16'>17</a>\u001b[0m                                           download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=17'>18</a>\u001b[0m test_data \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mCIFAR10(root\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./dataset\u001b[39m\u001b[39m\"\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, transform\u001b[39m=\u001b[39mtorchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=18'>19</a>\u001b[0m                                          download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=20'>21</a>\u001b[0m \u001b[39m# length 长度\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torchvision/datasets/cifar.py:65\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain \u001b[39m=\u001b[39m train  \u001b[39m# training set or test set\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload()\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_integrity():\n\u001b[1;32m     68\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataset not found or corrupted.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m     69\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39m You can use download=True to download it\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torchvision/datasets/cifar.py:143\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFiles already downloaded and verified\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m download_and_extract_archive(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot, filename\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, md5\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtgz_md5)\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torchvision/datasets/utils.py:413\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m filename:\n\u001b[1;32m    411\u001b[0m     filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(url)\n\u001b[0;32m--> 413\u001b[0m download_url(url, download_root, filename, md5)\n\u001b[1;32m    415\u001b[0m archive \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    416\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mExtracting \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(archive, extract_root))\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torchvision/datasets/utils.py:139\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mDownloading \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m url \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m fpath)\n\u001b[0;32m--> 139\u001b[0m     _urlretrieve(url, fpath)\n\u001b[1;32m    140\u001b[0m \u001b[39mexcept\u001b[39;00m (urllib\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mURLError, \u001b[39mIOError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m url[:\u001b[39m5\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torchvision/datasets/utils.py:33\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mwith\u001b[39;00m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(url, headers\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m: USER_AGENT})) \u001b[39mas\u001b[39;00m response:\n\u001b[1;32m     32\u001b[0m     \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mlength) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m---> 33\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mlambda\u001b[39;00m: response\u001b[39m.\u001b[39mread(chunk_size), \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     34\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk:\n\u001b[1;32m     35\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torchvision/datasets/utils.py:33\u001b[0m, in \u001b[0;36m_urlretrieve.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mwith\u001b[39;00m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(url, headers\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m: USER_AGENT})) \u001b[39mas\u001b[39;00m response:\n\u001b[1;32m     32\u001b[0m     \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mlength) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m---> 33\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mlambda\u001b[39;00m: response\u001b[39m.\u001b[39;49mread(chunk_size), \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     34\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk:\n\u001b[1;32m     35\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# VGG模型\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 导入VGG模型\n",
    "from VGGmodel import *\n",
    "\n",
    "# 准备数据集\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from VGG\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"./dataset\", train=True, transform=torchvision.transforms.ToTensor(),\n",
    "                                          download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"./dataset\", train=False, transform=torchvision.transforms.ToTensor(),\n",
    "                                         download=True)\n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 如果train_data_size=10, 训练数据集的长度为：10\n",
    "print(f\"训练数据集的长度为：{train_data_size}\")\n",
    "print(f\"测试数据集的长度为：{test_data_size}\")\n",
    "\n",
    "# 利用 DataLoader 来加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "vgg = VGG()\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 创建网络模型\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        # 网络序列\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "vgg = VGG()\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器\n",
    "# 调整速率\n",
    "learning_rate = 0.01\n",
    "# 1e-2=1 x (10)^(-2) = 1 /100 = 0.01\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(vgg.parameters(), lr=learning_rate)\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 3\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"./logs_VGGtrain\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(f\"-------第 {i+1} 轮训练开始-------\")\n",
    "\n",
    "    # 训练步骤开始\n",
    "    vgg.train()\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = vgg(imgs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step = total_train_step + 1\n",
    "        # 每一百次输出\n",
    "        if total_train_step % 100 == 0:\n",
    "            # item()转化为数字\n",
    "            print(\"训练次数：{}, Loss: {}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "    # 测试步骤开始\n",
    "    vgg.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            outputs = vgg(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_test_loss = total_test_loss + loss.item()\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "\n",
    "    print(\"整体测试集上的Loss: {}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率: {}\".format(total_accuracy/test_data_size))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy /\n",
    "                      test_data_size, total_test_step)\n",
    "    total_test_step = total_test_step + 1\n",
    "\n",
    "    torch.save(\n",
    "        vgg, \"/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/Pytorch/demo1/vggmodel/vgg_{}.pth\".format(i))\n",
    "    print(\"模型已保存\")\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 14 20:42:01 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| 48%   42C    P2    53W / 165W |   1266MiB /  6144MiB |     39%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1088      G   /usr/lib/xorg/Xorg                169MiB |\n",
      "|    0   N/A  N/A      1403      G   /usr/bin/kwin_x11                  51MiB |\n",
      "|    0   N/A  N/A      1414      G   /usr/bin/plasmashell               34MiB |\n",
      "|    0   N/A  N/A      1488      G   /usr/bin/ksysguard                  2MiB |\n",
      "|    0   N/A  N/A    475394      C   ...3/envs/RockLab/bin/python     1001MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b40e8fefbbad258a66ad4b3a1c9d5cec9c956cca3c9d68730a2d3ef07128da02"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('RockLab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
