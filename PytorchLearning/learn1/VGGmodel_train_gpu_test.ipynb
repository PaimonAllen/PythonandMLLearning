{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# VGG模型，GPU模式2\n",
    "# import\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# from model import *\n",
    "# 准备数据集\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyData object at 0x7f0089548df0>\n",
      "<__main__.MyData object at 0x7f0089548c70>\n"
     ]
    }
   ],
   "source": [
    "# 导入数据\n",
    "writer = SummaryWriter(\"logs\")\n",
    "\n",
    "class MyData(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, image_dir, label_dir, transform):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.label_path = os.path.join(self.root_dir, self.label_dir)\n",
    "        self.image_path = os.path.join(self.root_dir, self.image_dir)\n",
    "        self.image_list = os.listdir(self.image_path)\n",
    "        self.label_list = os.listdir(self.label_path)\n",
    "        self.transform = transform\n",
    "        # 因为label 和 Image文件名相同，进行一样的排序，可以保证取出的数据和label是一一对应的\n",
    "        self.image_list.sort()\n",
    "        self.label_list.sort()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_list[idx]\n",
    "        label_name = self.label_list[idx]\n",
    "        img_item_path = os.path.join(self.root_dir, self.image_dir, img_name)\n",
    "        label_item_path = os.path.join(self.root_dir, self.label_dir, label_name)\n",
    "        img = Image.open(img_item_path)\n",
    "\n",
    "        with open(label_item_path, 'r') as f:\n",
    "            label = f.readline()\n",
    "\n",
    "        # img = np.array(img)\n",
    "        img = self.transform(img)\n",
    "        sample = {'img': img, 'label': label}\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.image_list) == len(self.label_list)\n",
    "        return len(self.image_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "    root_dir = \"/home/tzr/Data_ML/Pytorch/demo1/hymenoptera_data/train\"\n",
    "    image_ants = \"ants_image\"\n",
    "    label_ants = \"ants_label\"\n",
    "    ants_dataset = MyData(root_dir, image_ants, label_ants, transform)\n",
    "    image_bees = \"bees_image\"\n",
    "    label_bees = \"bees_label\"\n",
    "    bees_dataset = MyData(root_dir, image_bees, label_bees, transform)\n",
    "    train_dataset = ants_dataset + bees_dataset\n",
    "\n",
    "    # transforms = transforms.Compose([transforms.Resize(256, 256)])\n",
    "    dataloader = DataLoader(train_dataset, batch_size=1, num_workers=2)\n",
    "\n",
    "    # writer.add_image('error', train_dataset[1]['img'])\n",
    "    writer.close()\n",
    "    # for i, j in enumerate(dataloader):\n",
    "    #     # imgs, labels = j\n",
    "    #     print(type(j))\n",
    "    #     print(i, j['img'].shape)\n",
    "    #     # writer.add_image(\"train_data_b2\", make_grid(j['img']), i)\n",
    "    \n",
    "    # writer.close()\n",
    "    print(ants_dataset)\n",
    "    print(bees_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集的长度为：50000\n",
      "测试数据集的长度为：10000\n",
      "-------第 1 轮训练开始-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tzr/anaconda3/envs/RockLab/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：100, Loss: 2.29002046585083\n",
      "训练次数：200, Loss: 2.263413429260254\n",
      "训练次数：300, Loss: 2.274883270263672\n",
      "训练次数：400, Loss: 2.2657995223999023\n",
      "训练次数：500, Loss: 2.1987926959991455\n",
      "训练次数：600, Loss: 1.874213695526123\n",
      "训练次数：700, Loss: 2.0364990234375\n",
      "训练次数：800, Loss: 2.0198280811309814\n",
      "训练次数：900, Loss: 2.190145969390869\n",
      "训练次数：1000, Loss: 2.015657663345337\n",
      "训练次数：1100, Loss: 1.6524579524993896\n",
      "训练次数：1200, Loss: 1.9604988098144531\n",
      "训练次数：1300, Loss: 1.6808092594146729\n",
      "训练次数：1400, Loss: 1.7955936193466187\n",
      "训练次数：1500, Loss: 1.619217872619629\n",
      "整体测试集上的Loss: 560.553390622139\n",
      "整体测试集上的正确率: 0.35819998383522034\n",
      "模型已保存\n",
      "-------第 2 轮训练开始-------\n",
      "训练次数：1600, Loss: 1.7613683938980103\n",
      "训练次数：1700, Loss: 1.6949918270111084\n",
      "训练次数：1800, Loss: 1.911799669265747\n",
      "训练次数：1900, Loss: 1.5295952558517456\n",
      "训练次数：2000, Loss: 1.5736370086669922\n",
      "训练次数：2100, Loss: 1.6100728511810303\n",
      "训练次数：2200, Loss: 1.3953156471252441\n",
      "训练次数：2300, Loss: 1.2554867267608643\n",
      "训练次数：2400, Loss: 1.5902752876281738\n",
      "训练次数：2500, Loss: 1.7013378143310547\n",
      "训练次数：2600, Loss: 1.4275325536727905\n",
      "训练次数：2700, Loss: 1.4461370706558228\n",
      "训练次数：2800, Loss: 1.4869822263717651\n",
      "训练次数：2900, Loss: 1.5540529489517212\n",
      "训练次数：3000, Loss: 1.5184773206710815\n",
      "训练次数：3100, Loss: 1.6144084930419922\n",
      "整体测试集上的Loss: 501.1218920946121\n",
      "整体测试集上的正确率: 0.42389997839927673\n",
      "模型已保存\n",
      "-------第 3 轮训练开始-------\n",
      "训练次数：3200, Loss: 1.3656340837478638\n",
      "训练次数：3300, Loss: 1.4741965532302856\n",
      "训练次数：3400, Loss: 1.6434805393218994\n",
      "训练次数：3500, Loss: 1.4629079103469849\n",
      "训练次数：3600, Loss: 1.5828735828399658\n",
      "训练次数：3700, Loss: 1.3569762706756592\n",
      "训练次数：3800, Loss: 1.621755838394165\n",
      "训练次数：3900, Loss: 1.3450162410736084\n",
      "训练次数：4000, Loss: 1.48978590965271\n",
      "训练次数：4100, Loss: 1.799250841140747\n",
      "训练次数：4200, Loss: 1.4593346118927002\n",
      "训练次数：4300, Loss: 1.4593777656555176\n",
      "训练次数：4400, Loss: 1.3368115425109863\n",
      "训练次数：4500, Loss: 1.4386032819747925\n",
      "训练次数：4600, Loss: 1.1851714849472046\n",
      "整体测试集上的Loss: 461.6477810740471\n",
      "整体测试集上的正确率: 0.4650999903678894\n",
      "模型已保存\n",
      "-------第 4 轮训练开始-------\n",
      "训练次数：4700, Loss: 1.3640676736831665\n",
      "训练次数：4800, Loss: 1.2793232202529907\n",
      "训练次数：4900, Loss: 1.3177484273910522\n",
      "训练次数：5000, Loss: 1.4683210849761963\n",
      "训练次数：5100, Loss: 1.3006705045700073\n",
      "训练次数：5200, Loss: 1.04218590259552\n",
      "训练次数：5300, Loss: 1.9392895698547363\n",
      "训练次数：5400, Loss: 1.3936703205108643\n",
      "训练次数：5500, Loss: 1.2423866987228394\n",
      "训练次数：5600, Loss: 1.4570342302322388\n",
      "训练次数：5700, Loss: 1.552161693572998\n",
      "训练次数：5800, Loss: 1.4618998765945435\n",
      "训练次数：5900, Loss: 0.9116588234901428\n",
      "训练次数：6000, Loss: 1.4738553762435913\n",
      "训练次数：6100, Loss: 1.5196118354797363\n",
      "训练次数：6200, Loss: 1.2204837799072266\n",
      "整体测试集上的Loss: 424.83103573322296\n",
      "整体测试集上的正确率: 0.5091999769210815\n",
      "模型已保存\n",
      "-------第 5 轮训练开始-------\n",
      "训练次数：6300, Loss: 1.4890708923339844\n",
      "训练次数：6400, Loss: 1.097049355506897\n",
      "训练次数：6500, Loss: 1.287738561630249\n",
      "训练次数：6600, Loss: 1.7141776084899902\n",
      "训练次数：6700, Loss: 1.5249642133712769\n",
      "训练次数：6800, Loss: 1.195394515991211\n",
      "训练次数：6900, Loss: 1.1441353559494019\n",
      "训练次数：7000, Loss: 1.453137755393982\n",
      "训练次数：7100, Loss: 1.1376066207885742\n",
      "训练次数：7200, Loss: 1.228805422782898\n",
      "训练次数：7300, Loss: 1.6250730752944946\n",
      "训练次数：7400, Loss: 1.3237249851226807\n",
      "训练次数：7500, Loss: 0.9483588337898254\n",
      "训练次数：7600, Loss: 1.0152523517608643\n",
      "训练次数：7700, Loss: 1.3350725173950195\n",
      "训练次数：7800, Loss: 1.014732003211975\n",
      "整体测试集上的Loss: 392.0243404507637\n",
      "整体测试集上的正确率: 0.5521999597549438\n",
      "模型已保存\n",
      "-------第 6 轮训练开始-------\n",
      "训练次数：7900, Loss: 1.3772234916687012\n",
      "训练次数：8000, Loss: 1.0920581817626953\n",
      "训练次数：8100, Loss: 1.0333114862442017\n",
      "训练次数：8200, Loss: 1.7213261127471924\n",
      "训练次数：8300, Loss: 1.2078006267547607\n",
      "训练次数：8400, Loss: 1.2327178716659546\n",
      "训练次数：8500, Loss: 0.8685298562049866\n",
      "训练次数：8600, Loss: 1.4238156080245972\n",
      "训练次数：8700, Loss: 1.11594820022583\n",
      "训练次数：8800, Loss: 0.9653199315071106\n",
      "训练次数：8900, Loss: 1.0080506801605225\n",
      "训练次数：9000, Loss: 1.222970962524414\n",
      "训练次数：9100, Loss: 1.0787521600723267\n",
      "训练次数：9200, Loss: 1.1210241317749023\n",
      "训练次数：9300, Loss: 1.695863127708435\n",
      "整体测试集上的Loss: 368.7555365562439\n",
      "整体测试集上的正确率: 0.5805000066757202\n",
      "模型已保存\n",
      "-------第 7 轮训练开始-------\n",
      "训练次数：9400, Loss: 1.4951388835906982\n",
      "训练次数：9500, Loss: 1.584396481513977\n",
      "训练次数：9600, Loss: 1.3247051239013672\n",
      "训练次数：9700, Loss: 1.0746031999588013\n",
      "训练次数：9800, Loss: 1.1044440269470215\n",
      "训练次数：9900, Loss: 1.0497617721557617\n",
      "训练次数：10000, Loss: 1.1088218688964844\n",
      "训练次数：10100, Loss: 1.1476943492889404\n",
      "训练次数：10200, Loss: 1.078956961631775\n",
      "训练次数：10300, Loss: 1.040156602859497\n",
      "训练次数：10400, Loss: 0.9883981347084045\n",
      "训练次数：10500, Loss: 1.108953833580017\n",
      "训练次数：10600, Loss: 1.1095879077911377\n",
      "训练次数：10700, Loss: 0.9354363083839417\n",
      "训练次数：10800, Loss: 1.106203556060791\n",
      "训练次数：10900, Loss: 1.0982275009155273\n",
      "整体测试集上的Loss: 352.0821525454521\n",
      "整体测试集上的正确率: 0.60589998960495\n",
      "模型已保存\n",
      "-------第 8 轮训练开始-------\n",
      "训练次数：11000, Loss: 0.7935613989830017\n",
      "训练次数：11100, Loss: 1.3320590257644653\n",
      "训练次数：11200, Loss: 0.8980979919433594\n",
      "训练次数：11300, Loss: 0.8638291358947754\n",
      "训练次数：11400, Loss: 1.1137434244155884\n",
      "训练次数：11500, Loss: 0.8965911865234375\n",
      "训练次数：11600, Loss: 0.8316546082496643\n",
      "训练次数：11700, Loss: 1.359208345413208\n",
      "训练次数：11800, Loss: 0.7650439739227295\n",
      "训练次数：11900, Loss: 1.129550814628601\n",
      "训练次数：12000, Loss: 1.3308892250061035\n",
      "训练次数：12100, Loss: 0.9601626396179199\n",
      "训练次数：12200, Loss: 0.8624230623245239\n",
      "训练次数：12300, Loss: 0.7448199391365051\n",
      "训练次数：12400, Loss: 0.9718472361564636\n",
      "训练次数：12500, Loss: 0.6937800049781799\n",
      "整体测试集上的Loss: 341.0193576812744\n",
      "整体测试集上的正确率: 0.6236000061035156\n",
      "模型已保存\n",
      "-------第 9 轮训练开始-------\n",
      "训练次数：12600, Loss: 0.8737086057662964\n",
      "训练次数：12700, Loss: 1.2558045387268066\n",
      "训练次数：12800, Loss: 1.4494565725326538\n",
      "训练次数：12900, Loss: 1.1719379425048828\n",
      "训练次数：13000, Loss: 1.1535894870758057\n",
      "训练次数：13100, Loss: 1.3518961668014526\n",
      "训练次数：13200, Loss: 1.0791579484939575\n",
      "训练次数：13300, Loss: 0.9033056497573853\n",
      "训练次数：13400, Loss: 0.7670778632164001\n",
      "训练次数：13500, Loss: 0.937286913394928\n",
      "训练次数：13600, Loss: 0.896794855594635\n",
      "训练次数：13700, Loss: 0.9822832345962524\n",
      "训练次数：13800, Loss: 0.9959005117416382\n",
      "训练次数：13900, Loss: 0.8324407935142517\n",
      "训练次数：14000, Loss: 1.345426082611084\n",
      "整体测试集上的Loss: 334.62376350164413\n",
      "整体测试集上的正确率: 0.6305999755859375\n",
      "模型已保存\n",
      "-------第 10 轮训练开始-------\n",
      "训练次数：14100, Loss: 1.1317481994628906\n",
      "训练次数：14200, Loss: 0.6979037523269653\n",
      "训练次数：14300, Loss: 0.7750644087791443\n",
      "训练次数：14400, Loss: 0.7811996340751648\n",
      "训练次数：14500, Loss: 0.640355110168457\n",
      "训练次数：14600, Loss: 0.9519956707954407\n",
      "训练次数：14700, Loss: 0.545577883720398\n",
      "训练次数：14800, Loss: 1.1073434352874756\n",
      "训练次数：14900, Loss: 1.0616577863693237\n",
      "训练次数：15000, Loss: 0.7423219680786133\n",
      "训练次数：15100, Loss: 1.348681092262268\n",
      "训练次数：15200, Loss: 0.9262738823890686\n",
      "训练次数：15300, Loss: 1.0162204504013062\n",
      "训练次数：15400, Loss: 0.729964017868042\n",
      "训练次数：15500, Loss: 0.7380329370498657\n",
      "训练次数：15600, Loss: 0.767579972743988\n",
      "整体测试集上的Loss: 328.95929777622223\n",
      "整体测试集上的正确率: 0.640500009059906\n",
      "模型已保存\n",
      "-------第 11 轮训练开始-------\n",
      "训练次数：15700, Loss: 1.107624888420105\n",
      "训练次数：15800, Loss: 1.187019944190979\n",
      "训练次数：15900, Loss: 0.6767681241035461\n",
      "训练次数：16000, Loss: 0.7697550058364868\n",
      "训练次数：16100, Loss: 0.8651289343833923\n",
      "训练次数：16200, Loss: 0.6860272884368896\n",
      "训练次数：16300, Loss: 0.6904181838035583\n",
      "训练次数：16400, Loss: 0.8481721878051758\n",
      "训练次数：16500, Loss: 0.8460097312927246\n",
      "训练次数：16600, Loss: 1.132165789604187\n",
      "训练次数：16700, Loss: 1.0461227893829346\n",
      "训练次数：16800, Loss: 0.9211248159408569\n",
      "训练次数：16900, Loss: 1.105733871459961\n",
      "训练次数：17000, Loss: 0.8539343476295471\n",
      "训练次数：17100, Loss: 1.0070027112960815\n",
      "整体测试集上的Loss: 325.6729847192764\n",
      "整体测试集上的正确率: 0.6464999914169312\n",
      "模型已保存\n",
      "-------第 12 轮训练开始-------\n",
      "训练次数：17200, Loss: 0.36167261004447937\n",
      "训练次数：17300, Loss: 0.9842248558998108\n",
      "训练次数：17400, Loss: 0.9794201254844666\n",
      "训练次数：17500, Loss: 0.8725430965423584\n",
      "训练次数：17600, Loss: 0.8386711478233337\n",
      "训练次数：17700, Loss: 0.9387446641921997\n",
      "训练次数：17800, Loss: 0.5166237354278564\n",
      "训练次数：17900, Loss: 0.9198643565177917\n",
      "训练次数：18000, Loss: 0.5710702538490295\n",
      "训练次数：18100, Loss: 0.8379843235015869\n",
      "训练次数：18200, Loss: 0.9677706956863403\n",
      "训练次数：18300, Loss: 0.8767793774604797\n",
      "训练次数：18400, Loss: 1.0530445575714111\n",
      "训练次数：18500, Loss: 0.9113308787345886\n",
      "训练次数：18600, Loss: 0.4371781647205353\n",
      "训练次数：18700, Loss: 0.7995644211769104\n",
      "整体测试集上的Loss: 321.68230098485947\n",
      "整体测试集上的正确率: 0.6524999737739563\n",
      "模型已保存\n",
      "-------第 13 轮训练开始-------\n",
      "训练次数：18800, Loss: 0.9285492300987244\n",
      "训练次数：18900, Loss: 0.6304640173912048\n",
      "训练次数：19000, Loss: 0.8119134902954102\n",
      "训练次数：19100, Loss: 0.8918716907501221\n",
      "训练次数：19200, Loss: 1.0203410387039185\n",
      "训练次数：19300, Loss: 1.0257281064987183\n",
      "训练次数：19400, Loss: 0.6344946026802063\n",
      "训练次数：19500, Loss: 0.9814516305923462\n",
      "训练次数：19600, Loss: 0.5950092673301697\n",
      "训练次数：19700, Loss: 0.7533083558082581\n",
      "训练次数：19800, Loss: 1.0999960899353027\n",
      "训练次数：19900, Loss: 0.8247403502464294\n",
      "训练次数：20000, Loss: 1.262445092201233\n",
      "训练次数：20100, Loss: 0.8655053973197937\n",
      "训练次数：20200, Loss: 0.471272349357605\n",
      "训练次数：20300, Loss: 1.110444188117981\n",
      "整体测试集上的Loss: 319.4670287966728\n",
      "整体测试集上的正确率: 0.6567999720573425\n",
      "模型已保存\n",
      "-------第 14 轮训练开始-------\n",
      "训练次数：20400, Loss: 0.6810622215270996\n",
      "训练次数：20500, Loss: 0.5194711089134216\n",
      "训练次数：20600, Loss: 1.0096921920776367\n",
      "训练次数：20700, Loss: 0.5853942036628723\n",
      "训练次数：20800, Loss: 0.5424174070358276\n",
      "训练次数：20900, Loss: 1.3695124387741089\n",
      "训练次数：21000, Loss: 0.8272392749786377\n",
      "训练次数：21100, Loss: 0.5190556645393372\n",
      "训练次数：21200, Loss: 0.8348740935325623\n",
      "训练次数：21300, Loss: 1.0306382179260254\n",
      "训练次数：21400, Loss: 0.6494131684303284\n",
      "训练次数：21500, Loss: 1.0126031637191772\n",
      "训练次数：21600, Loss: 0.9330577254295349\n",
      "训练次数：21700, Loss: 0.8866807818412781\n",
      "训练次数：21800, Loss: 0.6275456547737122\n",
      "整体测试集上的Loss: 317.8370323777199\n",
      "整体测试集上的正确率: 0.6609999537467957\n",
      "模型已保存\n",
      "-------第 15 轮训练开始-------\n",
      "训练次数：21900, Loss: 0.618124783039093\n",
      "训练次数：22000, Loss: 0.7512995004653931\n",
      "训练次数：22100, Loss: 0.6138957142829895\n",
      "训练次数：22200, Loss: 0.7702904343605042\n",
      "训练次数：22300, Loss: 0.7191289663314819\n",
      "训练次数：22400, Loss: 0.8619313836097717\n",
      "训练次数：22500, Loss: 0.8231001496315002\n",
      "训练次数：22600, Loss: 1.043951392173767\n",
      "训练次数：22700, Loss: 0.6934776306152344\n",
      "训练次数：22800, Loss: 0.3856915831565857\n",
      "训练次数：22900, Loss: 0.782470166683197\n",
      "训练次数：23000, Loss: 0.5770547986030579\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     75\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 76\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mvgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, targets)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# 优化器优化模型\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mVGG.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 38\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torch/nn/modules/conv.py:439\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    437\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    438\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root=\"./dataset\", train=True, transform=torchvision.transforms.ToTensor(),\n",
    "                                          download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"./dataset\", train=False, transform=torchvision.transforms.ToTensor(),\n",
    "                                         download=True)\n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 数据长度\n",
    "print(\"训练数据集的长度为：{}\".format(train_data_size))\n",
    "print(\"测试数据集的长度为：{}\".format(test_data_size))\n",
    "\n",
    "\n",
    "# 利用 DataLoader 来加载数据集\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_data, batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size)\n",
    "\n",
    "# 创建网络模型\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "vgg = VGG()\n",
    "vgg = vgg.to(device)\n",
    "\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    loss_fn = loss_fn.cuda()\n",
    "# 优化器\n",
    "# learning_rate = 0.01\n",
    "# 1e-2=1 x (10)^(-2) = 1 /100 = 0.01\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(vgg.parameters(), lr=learning_rate)\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 100\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"./logs_train\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-------第 {} 轮训练开始-------\".format(i+1))\n",
    "\n",
    "    # 训练步骤开始\n",
    "    vgg.train()\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = vgg(imgs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step = total_train_step + 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}, Loss: {}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "    # 测试步骤开始\n",
    "    vgg.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = vgg(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_test_loss = total_test_loss + loss.item()\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "\n",
    "    print(\"整体测试集上的Loss: {}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率: {}\".format(total_accuracy/test_data_size))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy /\n",
    "                      test_data_size, total_test_step)\n",
    "    total_test_step = total_test_step + 1\n",
    "\n",
    "    torch.save(\n",
    "        vgg, \"/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/Pytorch/demo1/vggmodel/vgg_{}.pth\".format(i))\n",
    "    print(\"模型已保存\")\n",
    "\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b40e8fefbbad258a66ad4b3a1c9d5cec9c956cca3c9d68730a2d3ef07128da02"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('RockLab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
