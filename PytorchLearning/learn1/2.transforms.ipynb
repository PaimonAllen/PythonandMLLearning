{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tzr/Documents/PycharmSYNC/PythonandMLLearning/PytorchLearning/learn1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "class MyData(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, image_dir, label_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.label_path = os.path.join(self.root_dir, self.label_dir)\n",
    "        self.image_path = os.path.join(self.root_dir, self.image_dir)\n",
    "        self.image_list = os.listdir(self.image_path)\n",
    "        self.label_list = os.listdir(self.label_path)\n",
    "        self.transform = transform\n",
    "        # 因为label 和 Image文件名相同，进行一样的排序，可以保证取出的数据和label是一一对应的\n",
    "        self.image_list.sort()\n",
    "        self.label_list.sort()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_list[idx]\n",
    "        label_name = self.label_list[idx]\n",
    "        img_item_path = os.path.join(self.root_dir, self.image_dir, img_name)\n",
    "        label_item_path = os.path.join(\n",
    "            self.root_dir, self.label_dir, label_name)\n",
    "        img = Image.open(img_item_path)\n",
    "        with open(label_item_path, 'r') as f:\n",
    "            label = f.readline()\n",
    "\n",
    "        if self.transform:\n",
    "            img = transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.image_list) == len(self.label_list)\n",
    "        return len(self.image_list)\n",
    "\n",
    "\n",
    "# transforms = transforms.Compose([transforms.Resize(256, 256)])\n",
    "# transforms.ToTensor将数据转化为Tensor\n",
    "transform = transforms.Compose([transforms.Resize(400), transforms.ToTensor()])\n",
    "root_dir = os.getcwd() + \"/dataset/bees1/train\"\n",
    "image_ants = \"ants_image\"\n",
    "label_ants = \"ants_label\"\n",
    "ants_dataset = MyData(root_dir, image_ants, label_ants, transform=transform)\n",
    "image_bees = \"bees_image\"\n",
    "label_bees = \"bees_label\"\n",
    "bees_dataset = MyData(root_dir, image_bees, label_bees, transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(ants_dataset)\n",
    "# 转化为tensor\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "img_path = os.getcwd() + \"/dataset/bees1/train/ants_image/0013035.jpg\"\n",
    "img = Image.open(img_path)\n",
    "tensor_trans = transforms.ToTensor()\n",
    "tensro_img = tensor_trans(img)\n",
    "# print(tensro_img)\n",
    "writer = SummaryWriter(\"logs_train\")\n",
    "\n",
    "writer.add_image(\"Tensor_imgtest\",tensro_img)\n",
    "\n",
    "writer.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3137)\n",
      "tensor(0.4275)\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "\n",
    "# print(ants_dataset)\n",
    "# 转化为tensor\n",
    "\n",
    "img_path = os.getcwd() + \"/dataset/bees1/train/ants_image/0013035.jpg\"\n",
    "img = Image.open(img_path)\n",
    "tensor_trans = transforms.ToTensor()\n",
    "tensor_img = tensor_trans(img)\n",
    "# print(tensro_img)\n",
    "writer = SummaryWriter(\"logs_train\")\n",
    "\n",
    "writer.add_image(\"Tensor_img\", tensro_img)\n",
    "\n",
    "print(tensor_img[0][0][0])\n",
    "trans_norm = transforms.Normalize([0.1, 0.1, 0.1], [0.5, 0.5, 0.5], [1, 2, 3])\n",
    "img_norm = trans_norm(tensor_img)\n",
    "writer.add_image(\"Normalise\", img_norm, 3) # 3 是第三步的意思\n",
    "print(tensor_img[0][0][0])\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 512)\n"
     ]
    }
   ],
   "source": [
    "# Resize\n",
    "print(img.size)\n",
    "trans_resize = transforms.Resize((512,512))\n",
    "img_resize = trans_resize(img)\n",
    "# img_resize 需要再重新转化为Tensor\n",
    "img_resize = tensor_trans(img_resize)\n",
    "writer.add_image(\"Resize\", img_resize, 0) \n",
    "\n",
    "# print(img_resize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 512)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# 等比例缩放\n",
    "# Resize\n",
    "print(img.size)\n",
    "trans_resize2 = transforms.Resize(120)\n",
    "# img_resize2 = trans_resize(img)\n",
    "# img_resize2 再重新转化为Tensor\n",
    "# img_resize2 = tensor_trans(img_resize2)\n",
    "trans_compose = transforms.Compose([trans_resize2,tensor_trans])\n",
    "img_resize_2=trans_compose(img)\n",
    "writer.add_image(\"Resize\", img_resize_2, 1)\n",
    "\n",
    "print(type(img_resize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.0\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "print(torchvision.__version__)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b40e8fefbbad258a66ad4b3a1c9d5cec9c956cca3c9d68730a2d3ef07128da02"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('RockLab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}