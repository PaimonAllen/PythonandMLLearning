{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from VGGmodel import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# VGG模型\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 导入VGG模型\n",
    "# from VGGmodel import *\n",
    "\n",
    "# 准备数据集\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from VGG\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"./dataset\", train=True, transform=torchvision.transforms.ToTensor(),\n",
    "                                          download=False)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"./dataset\", train=False, transform=torchvision.transforms.ToTensor(),\n",
    "                                         download=False)\n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 如果train_data_size=10, 训练数据集的长度为：10\n",
    "print(f\"训练数据集的长度为：{train_data_size}\")\n",
    "print(f\"测试数据集的长度为：{test_data_size}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集的长度为：50000\n",
      "测试数据集的长度为：10000\n",
      "-------第 1 轮训练开始-------\n",
      "训练次数：100, Loss: 2.293867349624634\n",
      "训练次数：200, Loss: 2.281412124633789\n",
      "训练次数：300, Loss: 2.2287890911102295\n",
      "训练次数：400, Loss: 2.1411569118499756\n",
      "训练次数：500, Loss: 2.0351834297180176\n",
      "训练次数：600, Loss: 2.0332090854644775\n",
      "训练次数：700, Loss: 1.9419347047805786\n",
      "整体测试集上的Loss: 306.1494377851486\n",
      "整体测试集上的正确率: 0.3028999865055084\n",
      "-------第 2 轮训练开始-------\n",
      "训练次数：800, Loss: 1.8389267921447754\n",
      "训练次数：900, Loss: 1.7882884740829468\n",
      "训练次数：1000, Loss: 1.883367657661438\n",
      "训练次数：1100, Loss: 1.957064151763916\n",
      "训练次数：1200, Loss: 1.6609960794448853\n",
      "训练次数：1300, Loss: 1.622560739517212\n",
      "训练次数：1400, Loss: 1.7055914402008057\n",
      "训练次数：1500, Loss: 1.7493705749511719\n",
      "整体测试集上的Loss: 290.8182909488678\n",
      "整体测试集上的正确率: 0.33239999413490295\n",
      "-------第 3 轮训练开始-------\n",
      "训练次数：1600, Loss: 1.6755839586257935\n",
      "训练次数：1700, Loss: 1.6274560689926147\n",
      "训练次数：1800, Loss: 1.9120426177978516\n",
      "训练次数：1900, Loss: 1.7224302291870117\n",
      "训练次数：2000, Loss: 1.9059244394302368\n",
      "训练次数：2100, Loss: 1.5097596645355225\n",
      "训练次数：2200, Loss: 1.4510303735733032\n",
      "训练次数：2300, Loss: 1.7384892702102661\n",
      "整体测试集上的Loss: 262.87681698799133\n",
      "整体测试集上的正确率: 0.39320001006126404\n",
      "-------第 4 轮训练开始-------\n",
      "训练次数：2400, Loss: 1.6886372566223145\n",
      "训练次数：2500, Loss: 1.3479375839233398\n",
      "训练次数：2600, Loss: 1.5835272073745728\n",
      "训练次数：2700, Loss: 1.6794800758361816\n",
      "训练次数：2800, Loss: 1.4905613660812378\n",
      "训练次数：2900, Loss: 1.593934178352356\n",
      "训练次数：3000, Loss: 1.3229832649230957\n",
      "训练次数：3100, Loss: 1.544224500656128\n",
      "整体测试集上的Loss: 256.87944877147675\n",
      "整体测试集上的正确率: 0.41130000352859497\n",
      "-------第 5 轮训练开始-------\n",
      "训练次数：3200, Loss: 1.3406569957733154\n",
      "训练次数：3300, Loss: 1.4469232559204102\n",
      "训练次数：3400, Loss: 1.4469043016433716\n",
      "训练次数：3500, Loss: 1.5482789278030396\n",
      "训练次数：3600, Loss: 1.5593208074569702\n",
      "训练次数：3700, Loss: 1.3366270065307617\n",
      "训练次数：3800, Loss: 1.2558283805847168\n",
      "训练次数：3900, Loss: 1.4717981815338135\n",
      "整体测试集上的Loss: 246.4869565963745\n",
      "整体测试集上的正确率: 0.4334999918937683\n",
      "-------第 6 轮训练开始-------\n",
      "训练次数：4000, Loss: 1.4253497123718262\n",
      "训练次数：4100, Loss: 1.4145574569702148\n",
      "训练次数：4200, Loss: 1.5588821172714233\n",
      "训练次数：4300, Loss: 1.2193440198898315\n",
      "训练次数：4400, Loss: 1.1608740091323853\n",
      "训练次数：4500, Loss: 1.3308730125427246\n",
      "训练次数：4600, Loss: 1.356415867805481\n",
      "整体测试集上的Loss: 234.46809840202332\n",
      "整体测试集上的正确率: 0.4595000147819519\n",
      "-------第 7 轮训练开始-------\n",
      "训练次数：4700, Loss: 1.3019967079162598\n",
      "训练次数：4800, Loss: 1.516654133796692\n",
      "训练次数：4900, Loss: 1.3358668088912964\n",
      "训练次数：5000, Loss: 1.354426622390747\n",
      "训练次数：5100, Loss: 0.974724292755127\n",
      "训练次数：5200, Loss: 1.3048442602157593\n",
      "训练次数：5300, Loss: 1.1926034688949585\n",
      "训练次数：5400, Loss: 1.3591264486312866\n",
      "整体测试集上的Loss: 223.6314172744751\n",
      "整体测试集上的正确率: 0.49059998989105225\n",
      "-------第 8 轮训练开始-------\n",
      "训练次数：5500, Loss: 1.2299286127090454\n",
      "训练次数：5600, Loss: 1.1376516819000244\n",
      "训练次数：5700, Loss: 1.213051438331604\n",
      "训练次数：5800, Loss: 1.1975252628326416\n",
      "训练次数：5900, Loss: 1.3142709732055664\n",
      "训练次数：6000, Loss: 1.5524007081985474\n",
      "训练次数：6100, Loss: 1.054543137550354\n",
      "训练次数：6200, Loss: 1.1041197776794434\n",
      "整体测试集上的Loss: 211.79496240615845\n",
      "整体测试集上的正确率: 0.5221999883651733\n",
      "-------第 9 轮训练开始-------\n",
      "训练次数：6300, Loss: 1.4305413961410522\n",
      "训练次数：6400, Loss: 1.1233420372009277\n",
      "训练次数：6500, Loss: 1.5347328186035156\n",
      "训练次数：6600, Loss: 1.1120296716690063\n",
      "训练次数：6700, Loss: 1.0267548561096191\n",
      "训练次数：6800, Loss: 1.1175537109375\n",
      "训练次数：6900, Loss: 1.0555344820022583\n",
      "训练次数：7000, Loss: 0.888005256652832\n",
      "整体测试集上的Loss: 200.4595900774002\n",
      "整体测试集上的正确率: 0.5478000044822693\n",
      "-------第 10 轮训练开始-------\n",
      "训练次数：7100, Loss: 1.2284793853759766\n",
      "训练次数：7200, Loss: 0.8790594935417175\n",
      "训练次数：7300, Loss: 1.10725998878479\n",
      "训练次数：7400, Loss: 0.8114864230155945\n",
      "训练次数：7500, Loss: 1.2252161502838135\n",
      "训练次数：7600, Loss: 1.2213469743728638\n",
      "训练次数：7700, Loss: 0.8115341663360596\n",
      "训练次数：7800, Loss: 1.235089659690857\n",
      "整体测试集上的Loss: 191.68399339914322\n",
      "整体测试集上的正确率: 0.5680000185966492\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# VGG模型\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 导入VGG模型\n",
    "from VGGmodel import *\n",
    "\n",
    "# 准备数据集\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from VGG\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"./dataset\", train=True, transform=torchvision.transforms.ToTensor(),\n",
    "                                          download=False)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"./dataset\", train=False, transform=torchvision.transforms.ToTensor(),\n",
    "                                         download=False)\n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 如果train_data_size=10, 训练数据集的长度为：10\n",
    "print(f\"训练数据集的长度为：{train_data_size}\")\n",
    "print(f\"测试数据集的长度为：{test_data_size}\")\n",
    "\n",
    "# 利用 DataLoader 来加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "vgg = VGG()\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器\n",
    "# 调整速率\n",
    "# 1e-2=1 x (10)^(-2) = 1 /100 = 0.01\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(vgg.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 10\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"logs_train\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(f\"-------第 {i+1} 轮训练开始-------\")\n",
    "\n",
    "    # 训练步骤开始\n",
    "    vgg.train()\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = vgg(imgs)\n",
    "        # 误差衡量与真实值的差距\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # 优化器优化模型\n",
    "        # 记得梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step += 1\n",
    "        # 每一百次输出\n",
    "        if total_train_step % 100 == 0:\n",
    "            # item()函数转化为数字\n",
    "            print(\"训练次数：{}, Loss: {}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar(\"train1_loss\", loss.item(), total_train_step)\n",
    "\n",
    "    # 测试步骤开始\n",
    "    vgg.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    # with torch.no_grad()表示没有梯度，不进行调优\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            outputs = vgg(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            # 计算总体的误差\n",
    "            total_test_loss = total_test_loss + loss.item()\n",
    "            # argmax获取横向最大值\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            # 计算整体的正确性\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "\n",
    "    print(\"整体测试集上的Loss: {}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率: {}\".format(total_accuracy/test_data_size))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy /\n",
    "                      test_data_size, total_test_step)\n",
    "    total_test_step = total_test_step + 1\n",
    "\n",
    "    # torch.save(\n",
    "    #     vgg, \"/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/Pytorch/demo1/vggmodel/vgg_{}.pth\".format(i))\n",
    "    # print(\"模型已保存\")\n",
    "\n",
    "writer.close()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 14 21:50:54 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 48%   40C    P0    37W / 165W |    596MiB /  6144MiB |      3%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla M40 24GB      On   | 00000000:03:00.0 Off |                  Off |\r\n",
      "| N/A   33C    P0    54W / 250W |      9MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1352      G   /usr/lib/xorg/Xorg                333MiB |\r\n",
      "|    0   N/A  N/A      1678      G   /usr/bin/kwin_x11                  45MiB |\r\n",
      "|    0   N/A  N/A      1682      G   /usr/bin/plasmashell               51MiB |\r\n",
      "|    0   N/A  N/A      1776      G   /usr/bin/ksysguard                  2MiB |\r\n",
      "|    0   N/A  N/A      1807      G   /usr/bin/ksysguard                  2MiB |\r\n",
      "|    0   N/A  N/A      2013      G   fcitx-qimpanel                     19MiB |\r\n",
      "|    0   N/A  N/A    305614      G   ...nlogin/bin/sunloginclient        8MiB |\r\n",
      "|    0   N/A  N/A    610165      G   ...bexec/kscreenlocker_greet      122MiB |\r\n",
      "|    1   N/A  N/A      1352      G   /usr/lib/xorg/Xorg                  3MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# VGG模型\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 导入VGG模型\n",
    "from VGGmodel import *\n",
    "\n",
    "# 准备数据集\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from VGG\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"./dataset\", train=True, transform=torchvision.transforms.ToTensor(),\n",
    "                                          download=False)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"./dataset\", train=False, transform=torchvision.transforms.ToTensor(),\n",
    "                                         download=False)\n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 如果train_data_size=10, 训练数据集的长度为：10\n",
    "print(f\"训练数据集的长度为：{train_data_size}\")\n",
    "print(f\"测试数据集的长度为：{test_data_size}\")\n",
    "\n",
    "# 利用 DataLoader 来加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "vgg = VGG()\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 创建网络模型\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        # 网络序列\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "vgg = VGG()\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器\n",
    "# 调整速率\n",
    "learning_rate = 0.01\n",
    "# 1e-2=1 x (10)^(-2) = 1 /100 = 0.01\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(vgg.parameters(), lr=learning_rate)\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 3\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"./logs_VGGtrain\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(f\"-------第 {i+1} 轮训练开始-------\")\n",
    "\n",
    "    # 训练步骤开始\n",
    "    vgg.train()\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = vgg(imgs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step = total_train_step + 1\n",
    "        # 每一百次输出\n",
    "        if total_train_step % 100 == 0:\n",
    "            # item()转化为数字\n",
    "            print(\"训练次数：{}, Loss: {}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "    # 测试步骤开始\n",
    "    vgg.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            outputs = vgg(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_test_loss = total_test_loss + loss.item()\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "\n",
    "    print(\"整体测试集上的Loss: {}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率: {}\".format(total_accuracy/test_data_size))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy /\n",
    "                      test_data_size, total_test_step)\n",
    "    total_test_step = total_test_step + 1\n",
    "\n",
    "    torch.save(\n",
    "        vgg, \"/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/Pytorch/demo1/vggmodel/vgg_{}.pth\".format(i))\n",
    "    print(\"模型已保存\")\n",
    "\n",
    "writer.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.2%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb Cell 1\u001B[0m in \u001B[0;36m<cell line: 16>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=11'>12</a>\u001B[0m \u001B[39mfrom\u001B[39;00m \u001B[39mtorch\u001B[39;00m\u001B[39m.\u001B[39;00m\u001B[39mutils\u001B[39;00m\u001B[39m.\u001B[39;00m\u001B[39mdata\u001B[39;00m \u001B[39mimport\u001B[39;00m DataLoader\n\u001B[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=13'>14</a>\u001B[0m \u001B[39m# from VGG\u001B[39;00m\n\u001B[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=15'>16</a>\u001B[0m train_data \u001B[39m=\u001B[39m torchvision\u001B[39m.\u001B[39;49mdatasets\u001B[39m.\u001B[39;49mCIFAR10(root\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39m./dataset\u001B[39;49m\u001B[39m\"\u001B[39;49m, train\u001B[39m=\u001B[39;49m\u001B[39mTrue\u001B[39;49;00m, transform\u001B[39m=\u001B[39;49mtorchvision\u001B[39m.\u001B[39;49mtransforms\u001B[39m.\u001B[39;49mToTensor(),\n\u001B[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=16'>17</a>\u001B[0m                                           download\u001B[39m=\u001B[39;49m\u001B[39mTrue\u001B[39;49;00m)\n\u001B[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=17'>18</a>\u001B[0m test_data \u001B[39m=\u001B[39m torchvision\u001B[39m.\u001B[39mdatasets\u001B[39m.\u001B[39mCIFAR10(root\u001B[39m=\u001B[39m\u001B[39m\"\u001B[39m\u001B[39m./dataset\u001B[39m\u001B[39m\"\u001B[39m, train\u001B[39m=\u001B[39m\u001B[39mFalse\u001B[39;00m, transform\u001B[39m=\u001B[39mtorchvision\u001B[39m.\u001B[39mtransforms\u001B[39m.\u001B[39mToTensor(),\n\u001B[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=18'>19</a>\u001B[0m                                          download\u001B[39m=\u001B[39m\u001B[39mTrue\u001B[39;00m)\n\u001B[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/Documents/GitHubSYNC/PythonandMLLearning/PytorchLearning/demo1/VGGmodel_train.ipynb#ch0000000vscode-remote?line=20'>21</a>\u001B[0m \u001B[39m# length 长度\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torchvision/datasets/cifar.py:65\u001B[0m, in \u001B[0;36mCIFAR10.__init__\u001B[0;34m(self, root, train, transform, target_transform, download)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtrain \u001B[39m=\u001B[39m train  \u001B[39m# training set or test set\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[39mif\u001B[39;00m download:\n\u001B[0;32m---> 65\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mdownload()\n\u001B[1;32m     67\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_check_integrity():\n\u001B[1;32m     68\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mRuntimeError\u001B[39;00m(\u001B[39m'\u001B[39m\u001B[39mDataset not found or corrupted.\u001B[39m\u001B[39m'\u001B[39m \u001B[39m+\u001B[39m\n\u001B[1;32m     69\u001B[0m                        \u001B[39m'\u001B[39m\u001B[39m You can use download=True to download it\u001B[39m\u001B[39m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torchvision/datasets/cifar.py:143\u001B[0m, in \u001B[0;36mCIFAR10.download\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    141\u001B[0m     \u001B[39mprint\u001B[39m(\u001B[39m'\u001B[39m\u001B[39mFiles already downloaded and verified\u001B[39m\u001B[39m'\u001B[39m)\n\u001B[1;32m    142\u001B[0m     \u001B[39mreturn\u001B[39;00m\n\u001B[0;32m--> 143\u001B[0m download_and_extract_archive(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49murl, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mroot, filename\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mfilename, md5\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mtgz_md5)\n",
      "File \u001B[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torchvision/datasets/utils.py:413\u001B[0m, in \u001B[0;36mdownload_and_extract_archive\u001B[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001B[0m\n\u001B[1;32m    410\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m filename:\n\u001B[1;32m    411\u001B[0m     filename \u001B[39m=\u001B[39m os\u001B[39m.\u001B[39mpath\u001B[39m.\u001B[39mbasename(url)\n\u001B[0;32m--> 413\u001B[0m download_url(url, download_root, filename, md5)\n\u001B[1;32m    415\u001B[0m archive \u001B[39m=\u001B[39m os\u001B[39m.\u001B[39mpath\u001B[39m.\u001B[39mjoin(download_root, filename)\n\u001B[1;32m    416\u001B[0m \u001B[39mprint\u001B[39m(\u001B[39m\"\u001B[39m\u001B[39mExtracting \u001B[39m\u001B[39m{}\u001B[39;00m\u001B[39m to \u001B[39m\u001B[39m{}\u001B[39;00m\u001B[39m\"\u001B[39m\u001B[39m.\u001B[39mformat(archive, extract_root))\n",
      "File \u001B[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torchvision/datasets/utils.py:139\u001B[0m, in \u001B[0;36mdownload_url\u001B[0;34m(url, root, filename, md5, max_redirect_hops)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[1;32m    138\u001B[0m     \u001B[39mprint\u001B[39m(\u001B[39m'\u001B[39m\u001B[39mDownloading \u001B[39m\u001B[39m'\u001B[39m \u001B[39m+\u001B[39m url \u001B[39m+\u001B[39m \u001B[39m'\u001B[39m\u001B[39m to \u001B[39m\u001B[39m'\u001B[39m \u001B[39m+\u001B[39m fpath)\n\u001B[0;32m--> 139\u001B[0m     _urlretrieve(url, fpath)\n\u001B[1;32m    140\u001B[0m \u001B[39mexcept\u001B[39;00m (urllib\u001B[39m.\u001B[39merror\u001B[39m.\u001B[39mURLError, \u001B[39mIOError\u001B[39;00m) \u001B[39mas\u001B[39;00m e:  \u001B[39m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    141\u001B[0m     \u001B[39mif\u001B[39;00m url[:\u001B[39m5\u001B[39m] \u001B[39m==\u001B[39m \u001B[39m'\u001B[39m\u001B[39mhttps\u001B[39m\u001B[39m'\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torchvision/datasets/utils.py:33\u001B[0m, in \u001B[0;36m_urlretrieve\u001B[0;34m(url, filename, chunk_size)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[39mwith\u001B[39;00m urllib\u001B[39m.\u001B[39mrequest\u001B[39m.\u001B[39murlopen(urllib\u001B[39m.\u001B[39mrequest\u001B[39m.\u001B[39mRequest(url, headers\u001B[39m=\u001B[39m{\u001B[39m\"\u001B[39m\u001B[39mUser-Agent\u001B[39m\u001B[39m\"\u001B[39m: USER_AGENT})) \u001B[39mas\u001B[39;00m response:\n\u001B[1;32m     32\u001B[0m     \u001B[39mwith\u001B[39;00m tqdm(total\u001B[39m=\u001B[39mresponse\u001B[39m.\u001B[39mlength) \u001B[39mas\u001B[39;00m pbar:\n\u001B[0;32m---> 33\u001B[0m         \u001B[39mfor\u001B[39;00m chunk \u001B[39min\u001B[39;00m \u001B[39miter\u001B[39m(\u001B[39mlambda\u001B[39;00m: response\u001B[39m.\u001B[39mread(chunk_size), \u001B[39m\"\u001B[39m\u001B[39m\"\u001B[39m):\n\u001B[1;32m     34\u001B[0m             \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m chunk:\n\u001B[1;32m     35\u001B[0m                 \u001B[39mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/RockLab/lib/python3.8/site-packages/torchvision/datasets/utils.py:33\u001B[0m, in \u001B[0;36m_urlretrieve.<locals>.<lambda>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[39mwith\u001B[39;00m urllib\u001B[39m.\u001B[39mrequest\u001B[39m.\u001B[39murlopen(urllib\u001B[39m.\u001B[39mrequest\u001B[39m.\u001B[39mRequest(url, headers\u001B[39m=\u001B[39m{\u001B[39m\"\u001B[39m\u001B[39mUser-Agent\u001B[39m\u001B[39m\"\u001B[39m: USER_AGENT})) \u001B[39mas\u001B[39;00m response:\n\u001B[1;32m     32\u001B[0m     \u001B[39mwith\u001B[39;00m tqdm(total\u001B[39m=\u001B[39mresponse\u001B[39m.\u001B[39mlength) \u001B[39mas\u001B[39;00m pbar:\n\u001B[0;32m---> 33\u001B[0m         \u001B[39mfor\u001B[39;00m chunk \u001B[39min\u001B[39;00m \u001B[39miter\u001B[39m(\u001B[39mlambda\u001B[39;00m: response\u001B[39m.\u001B[39;49mread(chunk_size), \u001B[39m\"\u001B[39m\u001B[39m\"\u001B[39m):\n\u001B[1;32m     34\u001B[0m             \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m chunk:\n\u001B[1;32m     35\u001B[0m                 \u001B[39mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/RockLab/lib/python3.8/http/client.py:459\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    456\u001B[0m \u001B[39mif\u001B[39;00m amt \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m    457\u001B[0m     \u001B[39m# Amount is given, implement using readinto\u001B[39;00m\n\u001B[1;32m    458\u001B[0m     b \u001B[39m=\u001B[39m \u001B[39mbytearray\u001B[39m(amt)\n\u001B[0;32m--> 459\u001B[0m     n \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mreadinto(b)\n\u001B[1;32m    460\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mmemoryview\u001B[39m(b)[:n]\u001B[39m.\u001B[39mtobytes()\n\u001B[1;32m    461\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    462\u001B[0m     \u001B[39m# Amount is not given (unbounded read) so we must check self.length\u001B[39;00m\n\u001B[1;32m    463\u001B[0m     \u001B[39m# and self.chunked\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/RockLab/lib/python3.8/http/client.py:503\u001B[0m, in \u001B[0;36mHTTPResponse.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    498\u001B[0m         b \u001B[39m=\u001B[39m \u001B[39mmemoryview\u001B[39m(b)[\u001B[39m0\u001B[39m:\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mlength]\n\u001B[1;32m    500\u001B[0m \u001B[39m# we do not use _safe_read() here because this may be a .will_close\u001B[39;00m\n\u001B[1;32m    501\u001B[0m \u001B[39m# connection, and the user is reading more bytes than will be provided\u001B[39;00m\n\u001B[1;32m    502\u001B[0m \u001B[39m# (for example, reading in 1k chunks)\u001B[39;00m\n\u001B[0;32m--> 503\u001B[0m n \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mfp\u001B[39m.\u001B[39;49mreadinto(b)\n\u001B[1;32m    504\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m n \u001B[39mand\u001B[39;00m b:\n\u001B[1;32m    505\u001B[0m     \u001B[39m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    506\u001B[0m     \u001B[39m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    507\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m~/anaconda3/envs/RockLab/lib/python3.8/socket.py:669\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    667\u001B[0m \u001B[39mwhile\u001B[39;00m \u001B[39mTrue\u001B[39;00m:\n\u001B[1;32m    668\u001B[0m     \u001B[39mtry\u001B[39;00m:\n\u001B[0;32m--> 669\u001B[0m         \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_sock\u001B[39m.\u001B[39;49mrecv_into(b)\n\u001B[1;32m    670\u001B[0m     \u001B[39mexcept\u001B[39;00m timeout:\n\u001B[1;32m    671\u001B[0m         \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_timeout_occurred \u001B[39m=\u001B[39m \u001B[39mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/RockLab/lib/python3.8/ssl.py:1241\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1237\u001B[0m     \u001B[39mif\u001B[39;00m flags \u001B[39m!=\u001B[39m \u001B[39m0\u001B[39m:\n\u001B[1;32m   1238\u001B[0m         \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\n\u001B[1;32m   1239\u001B[0m           \u001B[39m\"\u001B[39m\u001B[39mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[39m%s\u001B[39;00m\u001B[39m\"\u001B[39m \u001B[39m%\u001B[39m\n\u001B[1;32m   1240\u001B[0m           \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m\u001B[39m__class__\u001B[39m)\n\u001B[0;32m-> 1241\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mread(nbytes, buffer)\n\u001B[1;32m   1242\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m   1243\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39msuper\u001B[39m()\u001B[39m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m~/anaconda3/envs/RockLab/lib/python3.8/ssl.py:1099\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1097\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[1;32m   1098\u001B[0m     \u001B[39mif\u001B[39;00m buffer \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[0;32m-> 1099\u001B[0m         \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_sslobj\u001B[39m.\u001B[39;49mread(\u001B[39mlen\u001B[39;49m, buffer)\n\u001B[1;32m   1100\u001B[0m     \u001B[39melse\u001B[39;00m:\n\u001B[1;32m   1101\u001B[0m         \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_sslobj\u001B[39m.\u001B[39mread(\u001B[39mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 14 20:42:01 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| 48%   42C    P2    53W / 165W |   1266MiB /  6144MiB |     39%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1088      G   /usr/lib/xorg/Xorg                169MiB |\n",
      "|    0   N/A  N/A      1403      G   /usr/bin/kwin_x11                  51MiB |\n",
      "|    0   N/A  N/A      1414      G   /usr/bin/plasmashell               34MiB |\n",
      "|    0   N/A  N/A      1488      G   /usr/bin/ksysguard                  2MiB |\n",
      "|    0   N/A  N/A    475394      C   ...3/envs/RockLab/bin/python     1001MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b40e8fefbbad258a66ad4b3a1c9d5cec9c956cca3c9d68730a2d3ef07128da02"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('RockLab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}