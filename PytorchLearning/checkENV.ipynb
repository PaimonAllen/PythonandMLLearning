{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------  ---------------------------------------------------\n",
      "sys.platform           linux\n",
      "Python                 3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]\n",
      "Numpy                  1.21.2\n",
      "DETECTRON2_ENV_MODULE  <not set>\n",
      "PyTorch                1.9.0\n",
      "PyTorch Debug Build    False\n",
      "torchvision            0.10.0\n",
      "CUDA available         True\n",
      "GPU 0                  NVIDIA GeForce RTX 2060\n",
      "CUDA_HOME              /usr\n",
      "NVCC                   Cuda compilation tools, release 10.1, V10.1.243\n",
      "Pillow                 9.0.1\n",
      "---------------------  ---------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "from tabulate import tabulate\n",
    "\n",
    "__all__ = [\"collect_env_info\"]\n",
    "\n",
    "\n",
    "def collect_torch_env():\n",
    "    try:\n",
    "        import torch.__config__\n",
    "\n",
    "        return torch.__config__.show()\n",
    "    except ImportError:\n",
    "        # compatible with older versions of pytorch\n",
    "        from torch.utils.collect_env import get_pretty_env_info\n",
    "\n",
    "        return get_pretty_env_info()\n",
    "\n",
    "\n",
    "\n",
    "# def get_env_module():\n",
    "#     var_name = \"DETECTRON2_ENV_MODULE\"\n",
    "#     return var_name, os.environ.get(var_name, \"<not set>\")\n",
    "\n",
    "\n",
    "def collect_env_info():\n",
    "    data = []\n",
    "    data.append((\"sys.platform\", sys.platform))\n",
    "    data.append((\"Python\", sys.version.replace(\"\\n\", \"\")))\n",
    "    data.append((\"Numpy\", np.__version__))\n",
    "\n",
    "    # data.append(get_env_module())\n",
    "    data.append((\"PyTorch\", torch.__version__))\n",
    "    data.append((\"PyTorch Debug Build\", torch.version.debug))\n",
    "    try:\n",
    "        data.append((\"torchvision\", torchvision.__version__))\n",
    "    except AttributeError:\n",
    "        data.append((\"torchvision\", \"unknown\"))\n",
    "\n",
    "    has_cuda = torch.cuda.is_available()\n",
    "    data.append((\"CUDA available\", has_cuda))\n",
    "    if has_cuda:\n",
    "        devices = defaultdict(list)\n",
    "        for k in range(torch.cuda.device_count()):\n",
    "            devices[torch.cuda.get_device_name(k)].append(str(k))\n",
    "        for name, devids in devices.items():\n",
    "            data.append((\"GPU \" + \",\".join(devids), name))\n",
    "\n",
    "        from torch.utils.cpp_extension import CUDA_HOME\n",
    "\n",
    "        data.append((\"CUDA_HOME\", str(CUDA_HOME)))\n",
    "\n",
    "        if CUDA_HOME is not None and os.path.isdir(CUDA_HOME):\n",
    "            try:\n",
    "                nvcc = os.path.join(CUDA_HOME, \"bin\", \"nvcc\")\n",
    "                nvcc = subprocess.check_output(\"'{}' -V | tail -n1\".format(nvcc), shell=True)\n",
    "                nvcc = nvcc.decode(\"utf-8\").strip()\n",
    "            except subprocess.SubprocessError:\n",
    "                nvcc = \"Not Available\"\n",
    "            data.append((\"NVCC\", nvcc))\n",
    "\n",
    "        cuda_arch_list = os.environ.get(\"TORCH_CUDA_ARCH_LIST\", None)\n",
    "        if cuda_arch_list:\n",
    "            data.append((\"TORCH_CUDA_ARCH_LIST\", cuda_arch_list))\n",
    "    data.append((\"Pillow\", PIL.__version__))\n",
    "\n",
    "    try:\n",
    "        import cv2\n",
    "\n",
    "        data.append((\"cv2\", cv2.__version__))\n",
    "    except ImportError:\n",
    "        pass\n",
    "    env_str = tabulate(data) + \"\\n\"\n",
    "    env_str += collect_torch_env()\n",
    "    return env_str\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(collect_env_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------  ---------------------------------------------------\n",
      "sys.platform           linux\n",
      "Python                 3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]\n",
      "Numpy                  1.21.2\n",
      "detectron2._C          failed to import\n",
      "DETECTRON2_ENV_MODULE  <not set>\n",
      "PyTorch                1.9.0\n",
      "PyTorch Debug Build    False\n",
      "torchvision            0.10.0\n",
      "CUDA available         True\n",
      "GPU 0                  NVIDIA GeForce RTX 2060\n",
      "CUDA_HOME              /usr\n",
      "NVCC                   Cuda compilation tools, release 10.1, V10.1.243\n",
      "Pillow                 9.0.1\n",
      "---------------------  ---------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "from tabulate import tabulate\n",
    "\n",
    "__all__ = [\"collect_env_info\"]\n",
    "\n",
    "\n",
    "def collect_torch_env():\n",
    "    try:\n",
    "        import torch.__config__\n",
    "\n",
    "        return torch.__config__.show()\n",
    "    except ImportError:\n",
    "        # compatible with older versions of pytorch\n",
    "        from torch.utils.collect_env import get_pretty_env_info\n",
    "\n",
    "        return get_pretty_env_info()\n",
    "\n",
    "\n",
    "def get_env_module():\n",
    "    var_name = \"DETECTRON2_ENV_MODULE\"\n",
    "    return var_name, os.environ.get(var_name, \"<not set>\")\n",
    "\n",
    "\n",
    "def collect_env_info():\n",
    "    data = []\n",
    "    data.append((\"sys.platform\", sys.platform))\n",
    "    data.append((\"Python\", sys.version.replace(\"\\n\", \"\")))\n",
    "    data.append((\"Numpy\", np.__version__))\n",
    "    try:\n",
    "        from detectron2 import _C\n",
    "    except ImportError:\n",
    "        data.append((\"detectron2._C\", \"failed to import\"))\n",
    "    else:\n",
    "        data.append((\"Detectron2 Compiler\", _C.get_compiler_version()))\n",
    "        data.append((\"Detectron2 CUDA Compiler\", _C.get_cuda_version()))\n",
    "\n",
    "    data.append(get_env_module())\n",
    "    data.append((\"PyTorch\", torch.__version__))\n",
    "    data.append((\"PyTorch Debug Build\", torch.version.debug))\n",
    "    try:\n",
    "        data.append((\"torchvision\", torchvision.__version__))\n",
    "    except AttributeError:\n",
    "        data.append((\"torchvision\", \"unknown\"))\n",
    "\n",
    "    has_cuda = torch.cuda.is_available()\n",
    "    data.append((\"CUDA available\", has_cuda))\n",
    "    if has_cuda:\n",
    "        devices = defaultdict(list)\n",
    "        for k in range(torch.cuda.device_count()):\n",
    "            devices[torch.cuda.get_device_name(k)].append(str(k))\n",
    "        for name, devids in devices.items():\n",
    "            data.append((\"GPU \" + \",\".join(devids), name))\n",
    "\n",
    "        from torch.utils.cpp_extension import CUDA_HOME\n",
    "\n",
    "        data.append((\"CUDA_HOME\", str(CUDA_HOME)))\n",
    "\n",
    "        if CUDA_HOME is not None and os.path.isdir(CUDA_HOME):\n",
    "            try:\n",
    "                nvcc = os.path.join(CUDA_HOME, \"bin\", \"nvcc\")\n",
    "                nvcc = subprocess.check_output(\"'{}' -V | tail -n1\".format(nvcc), shell=True)\n",
    "                nvcc = nvcc.decode(\"utf-8\").strip()\n",
    "            except subprocess.SubprocessError:\n",
    "                nvcc = \"Not Available\"\n",
    "            data.append((\"NVCC\", nvcc))\n",
    "\n",
    "        cuda_arch_list = os.environ.get(\"TORCH_CUDA_ARCH_LIST\", None)\n",
    "        if cuda_arch_list:\n",
    "            data.append((\"TORCH_CUDA_ARCH_LIST\", cuda_arch_list))\n",
    "    data.append((\"Pillow\", PIL.__version__))\n",
    "\n",
    "    try:\n",
    "        import cv2\n",
    "\n",
    "        data.append((\"cv2\", cv2.__version__))\n",
    "    except ImportError:\n",
    "        pass\n",
    "    env_str = tabulate(data) + \"\\n\"\n",
    "    env_str += collect_torch_env()\n",
    "    return env_str\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(collect_env_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "    print('test')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2\n"
     ]
    }
   ],
   "source": [
    "    print('test2')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test3\n"
     ]
    }
   ],
   "source": [
    "    print('test3')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "    print(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sync\n"
     ]
    }
   ],
   "source": [
    "print('sync')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syncok\n"
     ]
    }
   ],
   "source": [
    "print('syncok')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('RockLab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b40e8fefbbad258a66ad4b3a1c9d5cec9c956cca3c9d68730a2d3ef07128da02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}